# Resources

## Workshop Repository and Documentation

The workshop repository on GitHub contains everything needed for the workshop. The repo includes documentation, reference prompts, example markdown snippets and schema as well as curated labs to practice.

* Repository: <a href="https://github.com/Harmonym/lab-time-for-agents"> https://github.com/Harmonym/lab-time-for-agents</a>

## Tools

* Agent building and controls platform <a href="https://ai.azure.com">Azure AI Foundry</a>
* <a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling">GitHub</a> copilot for pair programming

## Learn resources

* The <a href="https://learn.microsoft.com/security/security-for-ai/">Security for AI collection</a> in MS Learn
* Adding <a href="https://docs.github.com/en/copilot/how-tos/configure-custom-instructions/add-personal-instructions">SDL instructions</a> to your GitHub Copilot
* <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/ai-red-teaming-agent"> Attack strategies</a>
* <a href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Taxonomy-of-Failure-Mode-in-Agentic-AI-Systems-Whitepaper.pdf">Novel AI failure taxonomy</a>
* Reference <a href="https://learn.microsoft.com/en-us/purview/audit-copilot#user-activities-with-copilot-and-ai-applications">AI logging schema</a>


## Prompting guidance

* <a href="https://github.com/Harmonym/lab-time-for-agents/blob/main/docs/docs/copilot-instructions.md">Effective custom instructions</a> for GitHub Copilot
* The anatomy of <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/system-message?tabs=top-techniques#summary-of-best-practices">system instructions</a>
* Guidance for <a href="https://learn.microsoft.com/en-us/microsoft-365-copilot/extensibility/declarative-agent-instructions">writing declaritive instructions</a> for agents
* Reference template for <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/safety-system-message-templates">safety system instructions</a>


## Safety & security tooling

* <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/content-filter-prompt-shields">Prompt Shields</a>
* <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/content-filter-prompt-shields#spotlighting-for-prompt-shields-preview">Spotlighting</a>
* <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators/agent-evaluators#task-adherence-output">Task adherence</a>
* <a href="https://github.com/Azure-Samples/azureai-samples/blob/main/scenarios/evaluate/Supported_Evaluation_Metrics/Agent_Evaluation/AI_Judge_Evaluator_Task_Adherence.ipynb">Set-up guide for Task Adherence evaluations</a>
* Types of <a href="https://learn.microsoft.com/en-us/azure/defender-for-cloud/alerts-ai-workloads">available AI alerts</a>


## AI Red Teaming

* <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/ai-red-teaming-agent">AI Red Teaming Agent</a>
* <a href="https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/evaluate/AI_RedTeaming"> Set-up the AI Red Teaming Agent</a>
* Run the <a href="https://github.com/Azure/PyRIT">Python Risk Identification Tool for Generative AI (PyRIT)</a>


## Designing for appropriate reliance
* Understanding <a href="https://www.microsoft.com/en-us/research/publication/overreliance-on-ai-literature-review/">inappropriate reliance</a>
* <a href="https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/overreliance-on-ai/overreliance-on-ai">Overreliance framework</a> for interaction design



## Thank you

Thank you for participating in this workshop! If you have any suggestions for improvements or encountered any problems while running this workshop, please let us know via <a href="https://github.com/Harmonym/lab-time-for-agents/issues">GitHub Issues</a>


