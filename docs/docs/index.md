# Agentic Safety for AI builders

## A 120-minute learning session and interactive workshop

Imagine you are an AI tool builder for a global shoe company. You are working to build tools that help teams to be more effective, alleviate common problems that impact their productivity, and automates tedius tasks so they can spend more time on the types of work they enjoy. After working with the teams to understand the source of their top areas of frustration and ideas for opportunities to ehance how they do their work, you identify a need for a conversational agent that can help the product teams in their brainstorming and design work. 

![Contoso running shoes](media/designers.png)

## What is an LLM-Powered AI Agent?

A Large Language Model (LLM) powered AI Agent is semi-autonomous software designed to achieve a given goal without requiring predefined steps or processes. Instead of following explicitly programmed instructions, the agent determines how to accomplish a task using instructions and context.

For example, if a user asks, "**what were the design characteristics of 1970s style running shoes**", the app doesn't rely on predefined logic for this request. Instead, the LLM interprets the request, manages the conversation flow and context, and orchestrates the necessary actions to produce a summary of the design elements that were common for that era.

Unlike traditional applications, where developers define the logic and workflows to support business processes, AI agents rely on the LLM. In these systems, prompt engineering, clear instructions, and tool development are critical to ensuring the app performs as intended.

## What is different about security for AI?

AI presents a variety of novel threats, in addition to inheriting most if not all traditional security risks. The fill AI architecture stack presents new attack surfaces as well as unlocks new techniques for cyber attackers. See [Top AI Threats](top-threats.md) for an overview of the most common AI threats. It is also important to recognise that strong cyber security practices across both AI and traditional software/hardware is more critical than ever because cyber attackers are also using AI to power their attack chains (increased speed & scale, more dynamic, hyper targeted & personalized).

## What is AI safety?

AI safety is the engineering and design practice of ensuring that you have considered what could go wrong with your AI system and you have plans in place. It involves evaluating your solution, defining the unique ways that AI can fail, understanding the human impacts of those failures, and designing safety controls into all layers of the stack. The goal of this is to alleviate potential harm, ensure you are prepared to respond when failures (inevitably occur), and are able to earn appropriate trust in the solution. <a href="https://www.microsoft.com/en-us/security/blog/2025/05/29/how-to-deploy-ai-safely/?msockid=09303f5212946e3303a12d0c13536fd6">Learn more about deploying AI safely</a>



