# Build-an-Agent Labs: Safety & Security Workshop

A hands-on, interactive 2-hour workshop for AI builders to implement essential safety and security techniques into custom agents. This workshop covers core security practices, Microsoft Safety System tools, and practical agent defense tactics.

## Who Is This For?

Anyone interested in building safet and secure agents. This includes developers, product managers, data scientists, vibe coders, and AI enthusiasts. No prior experience with Foundry Agent Service or is required.

## 🎯 Learning Objectives

By the end of this workshop, you will be able to:
- Recognize top AI threats in agent development
- Apply Security Development Lifecycle (SDL) principles
- Implement effective behavior constraints
- Integrate Microsoft safety system tools (Prompt Shield, Spotlighting, Task Adherence)
- Test agents with adversarial (red team) techniques
- Set up logging and monitoring for agent observability
- Design for appropriate reliance

## 📚 Workshop Structure

### Introduction _(05 min)_

### Today's AI threat landscape _(10 min)_

### Example agent _(05 min)_

### System architecture _(05 min)_

### Lab 1: SDL-Oriented Instructions _(05 min)_
Implement Security Development Lifecycle principles in your agent’s instructions.

### Lab 2: Behavior Constraints _(15 min)_
Build system messages to define agent boundaries.

### Lab 3: Microsoft Safety System Tools _(15 min)_
Integrate Prompt Shield, Spotlighting, and Task Adherence.

### Lab 4: Red Team Testing _(15 min)_
Test your agent’s security using adversarial techniques.

### Lab 5: Logging & Monitoring _(15 min)_
Implement logging and basic monitoring for your agents.

### Lab 6: Minotiring & Alerting _(15 min)_
Implement logging and basic monitoring for your agents.

> _Optional Extension: Human-in-the-loop (HITL) Design_(15 min)_

### Recap and close-out _(05 min)_


## 🚀 Quick Start

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Harmonym/lab-time-for-agents.git
   cd lab-time-for-agents
   ```

## 📋 Prerequisites

- Python 3.8 or higher
- Basic understanding of AI/ML concepts
- Azure subscription (for Microsoft Safety System tools)

## 🔧 Tools & Technologies

- **AI building platform**: Microsoft AI Foundry
- **Safety tools**: Microsoft Prompt Shield, Azure Content Safety
- **Monitoring**: Microsoft Defender for Cloud
- **Testing**: AI Red Team agent

## 📖 Additional Resources

- [Security for AI](https://www.microsoft.com/en-us/ai/responsible-ai](https://learn.microsoft.com/en-us/security/security-for-ai/))
- [OWASP AI Security](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

## 🤝 Contributing

Please see our [contributing guidelines](CONTRIBUTING.md) for information on how to contribute to this project.

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
````
