# Build-an-Agent Labs: Safety & Security Workshop

A hands-on, interactive 2-hour workshop for AI builders to implement essential safety and security techniques into custom agents. This workshop covers core security practices, Microsoft Safety System tools, and practical agent defense tactics.
https://aka.ms/agentsecuritylab/


## Who Is This For?

Anyone interested in building safet and secure agents. This includes developers, product managers, data scientists, vibe coders, and AI enthusiasts. No prior experience with Foundry Agent Service or is required.

## üéØ Learning Objectives

By the end of this workshop, you will be able to:
- Recognize top AI threats in agent development
- Apply Security Development Lifecycle (SDL) principles
- Implement effective behavior constraints
- Integrate Microsoft safety system tools (Prompt Shield, Spotlighting, Task Adherence)
- Test agents with adversarial (red team) techniques
- Set up logging and monitoring for agent observability
- Design for appropriate reliance

## üìö Workshop Structure

1. **Introduction** _(05 min)_

3. **Today's AI threat landscape** _(10 min)_

4. **Example agent** _(05 min)_

5. **System architecture** _(05 min)_

6. **Lab 1**: SDL-Oriented Instructions _(05 min)_
Implement Security Development Lifecycle principles in your agent‚Äôs instructions.

7. **Lab 2**: Behavior Constraints _(15 min)_
Build system messages to define agent boundaries.

8. **Lab 3**: Microsoft Safety System Tools _(15 min)_
Integrate Prompt Shield, Spotlighting, and Task Adherence.

9. **Lab 4**: Red Team Testing _(15 min)_
Test your agent‚Äôs security using adversarial techniques.

10. **Lab 5**: Logging & Monitoring _(15 min)_
Implement logging and basic monitoring for your agents.

11. **Lab 6**: Monitoring & Alerting _(15 min)_
Implement logging and basic monitoring for your agents.

12. _Optional Extension: **Lab 7** Human-in-the-loop (HITL) Design_(15 min)_

13. **Recap and close-out** _(05 min)_


## üöÄ Quick Start

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Harmonym/lab-time-for-agents.git
   cd lab-time-for-agents
   ```

## üìã Prerequisites

- Python 3.8 or higher
- Basic understanding of AI/ML concepts
- Azure subscription (for Microsoft Safety System tools)

## üîß Tools & Technologies

- **AI building platform**: Microsoft AI Foundry
- **Safety tools**: Microsoft Prompt Shield, Azure Content Safety
- **Monitoring**: Microsoft Defender for Cloud
- **Testing**: AI Red Team agent

## üìñ Additional Resources

- [Security for AI](https://www.microsoft.com/en-us/ai/responsible-ai](https://learn.microsoft.com/en-us/security/security-for-ai/))
- [OWASP AI Security](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

## ü§ù Contributing

Please see our [contributing guidelines](CONTRIBUTING) for information on how to contribute to this project.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üìÑ Trademark

Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft‚Äôs Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party‚Äôs policies.


