# Build-an-Agent Labs: Safety & Security Workshop

A hands-on, interactive 2-hour workshop for AI builders to implement essential safety and security techniques into custom agents. This workshop covers core security practices, Microsoft Safety System tools, and practical agent defense tactics.

## 🎯 Learning Objectives

By the end of this workshop, you will be able to:
- Recognize top AI threats in agent development
- Apply Security Development Lifecycle (SDL) principles
- Implement effective behavior constraints
- Integrate Microsoft safety system tools (Prompt Shield, Spotlighting, Task Adherence)
- Test agents with adversarial (red team) techniques
- Set up logging and monitoring for agent observability
- Design for appropriate reliance

## 📚 Workshop Structure

### Lab 1: SDL-Oriented Instructions _(05 min)_
Implement Security Development Lifecycle principles in your agent’s instructions.
- **Location**: [`docs/docs/lab-01-sdl-instructions/`](docs/docs/lab-01-sdl-instructions/)

### Lab 2: Behavior Constraints _(15 min)_
Build system messages to define agent boundaries.
- **Location**: [`docs/docs/lab-02-constraints/`](docs/docs/lab-02-constraints/)

### Lab 3: Microsoft Safety System Tools _(15 min)_
Integrate Prompt Shield, Spotlighting, and Task Adherence.
- **Location**: [`labs/03-safety-systems/`](labs/03-safety-systems/)

### Lab 4: Red Team Testing _(15 min)_
Test your agent’s security using adversarial techniques.
- **Location**: [`labs/04-testing/`](labs/04-testing/)

### Lab 5: Logging & Monitoring _(15 min)_
Implement logging and basic monitoring for your agents.
- **Location**: [`labs/05-logging/`](labs/05-logging/)

### Lab 6: Minotiring & Alerting _(15 min)_
Implement logging and basic monitoring for your agents.
- **Location**: [`labs/06-monitoring-alerting/`](labs/06-monitoring-alerting/)

> _Optional Extension: Human-in-the-loop (HITL) Design_(15 min)_
> - See [`labs/07-hitl/`](labs/07-hitl/) for further exploration after the workshop.

## 🚀 Quick Start

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Harmonym/lab-time-for-agents.git
   cd lab-time-for-agents
   ```

## 📋 Prerequisites

- Python 3.8 or higher
- Basic understanding of AI/ML concepts
- Azure subscription (for Microsoft Safety System tools)

## 🔧 Tools & Technologies

- **AI building platform**: Microsoft AI Foundry
- **Safety tools**: Microsoft Prompt Shield, Azure Content Safety
- **Monitoring**: Microsoft Defender for Cloud
- **Testing**: AI Red Team agent

## 📖 Additional Resources

- [Security for AI](https://www.microsoft.com/en-us/ai/responsible-ai](https://learn.microsoft.com/en-us/security/security-for-ai/))
- [OWASP AI Security](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

## 🤝 Contributing

Please see our [contributing guidelines](CONTRIBUTING.md) for information on how to contribute to this project.

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
````
